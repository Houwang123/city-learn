{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citylearn.citylearn import CityLearnEnv\n",
    "import time, random, typing, cProfile, traceback\n",
    "import numpy as np\n",
    "\n",
    "def action_space_to_dict(aspace):\n",
    "    \"\"\" Only for box space \"\"\"\n",
    "    return { \"high\": aspace.high,\n",
    "             \"low\": aspace.low,\n",
    "             \"shape\": aspace.shape,\n",
    "             \"dtype\": str(aspace.dtype)\n",
    "    }\n",
    "\n",
    "def env_reset(env):\n",
    "    observations = env.reset()\n",
    "    action_space = env.action_space\n",
    "    observation_space = env.observation_space\n",
    "    building_info = env.get_building_information()\n",
    "    building_info = list(building_info.values())\n",
    "    action_space_dicts = [action_space_to_dict(asp) for asp in action_space]\n",
    "    observation_space_dicts = [action_space_to_dict(osp) for osp in observation_space]\n",
    "    obs_dict = {\"action_space\": action_space_dicts,\n",
    "                \"observation_space\": observation_space_dicts,\n",
    "                \"building_info\": building_info,\n",
    "                \"observation\": observations }\n",
    "    return obs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constants:\n",
    "    episodes = 3\n",
    "    schema_path = './data/citylearn_challenge_2022_phase_1/schema.json'\n",
    "\n",
    "from agents.agents import ddpg\n",
    "from agents.networks import central_critic, comm_net\n",
    "from agents.features import *\n",
    "from rewards import get_reward, rewards\n",
    "\n",
    "from agents.orderenforcingwrapper import OrderEnforcingAgent\n",
    "\n",
    "agent_wrapper = OrderEnforcingAgent(agent = ddpg.DDPGAgent(\n",
    "    actor = comm_net.CommNet,\n",
    "    critic = central_critic.CentralCritic,\n",
    "    actor_feature=BaseFeatureEngineer(),\n",
    "    critic_feature=CentralCriticEngineer(BaseFeatureEngineer())\n",
    "))\n",
    "\n",
    "get_reward.reward_function = rewards.default_reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "README@ChenRang:\n",
    "TODO: Adjust this for training purposes\n",
    "1. Logging (Debugging module and experimenter module)\n",
    "2. Saving episode (check with zzx for API details)\n",
    "3. JSON parameter setup instead of hardcoded values\n",
    "4. Reward selection system (also integrate into JSON)\n",
    "5. Automated unit tests for different modules\n",
    "6. Automated profiling\n",
    "7. Neptune AI / MLFlow experiment logging (low priority)\n",
    "8. Multiprocessing (low priority)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    env = CityLearnEnv(schema=Constants.schema_path)\n",
    "\n",
    "    obs_dict = env_reset(env)\n",
    "\n",
    "    agent = agent_wrapper\n",
    "    agent_time_elapsed = 0\n",
    "\n",
    "    step_start = time.perf_counter()\n",
    "    actions = agent.register_reset(obs_dict)\n",
    "    agent_time_elapsed += time.perf_counter()- step_start\n",
    "\n",
    "    episodes_completed = 0\n",
    "    num_steps = 0\n",
    "    interrupted = False\n",
    "    episode_metrics = []\n",
    "    try:\n",
    "        while True:\n",
    "            observations, _, done, _ = env.step(actions)\n",
    "            if done:\n",
    "                episodes_completed += 1\n",
    "                metrics_t = env.evaluate()\n",
    "                metrics = {\"price_cost\": metrics_t[0], \"emmision_cost\": metrics_t[1]}\n",
    "                if np.any(np.isnan(metrics_t)):\n",
    "                    raise ValueError(\"Episode metrics are nan, please contant organizers\")\n",
    "                episode_metrics.append(metrics)\n",
    "                print(f\"Episode complete: {episodes_completed} | Latest episode metrics: {metrics}\", )\n",
    "\n",
    "                obs_dict = env_reset(env)\n",
    "\n",
    "                step_start = time.perf_counter()\n",
    "                actions = agent.register_reset(obs_dict)\n",
    "                agent_time_elapsed += time.perf_counter()- step_start\n",
    "            else:\n",
    "                step_start = time.perf_counter()\n",
    "                actions = agent.compute_action(observations)\n",
    "                agent_time_elapsed += time.perf_counter()- step_start\n",
    "            \n",
    "            num_steps += 1\n",
    "            if num_steps % 1000 == 0:\n",
    "                print(f\"Num Steps: {num_steps}, Num episodes: {episodes_completed}\")\n",
    "\n",
    "            if episodes_completed >= Constants.episodes:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"========================= Stopping Evaluation =========================\")\n",
    "        interrupted = True\n",
    "\n",
    "    if not interrupted:\n",
    "        print(\"=========================Completed=========================\")\n",
    "\n",
    "    if len(episode_metrics) > 0:\n",
    "        print(\"Average Price Cost:\", np.mean([e['price_cost'] for e in episode_metrics]))\n",
    "        print(\"Average Emmision Cost:\", np.mean([e['emmision_cost'] for e in episode_metrics]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "pr.run('train()')\n",
    "\n",
    "pr.disable()\n",
    "pr.print_stats(sort='time')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8eba5e1ea696c6f52a891e98e9d85dda3469a737f80f8873b5aac718fce636c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
